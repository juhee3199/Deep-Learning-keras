{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch8-1 text generation with LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7RMVkCMO5GiGchanW4dky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhee3199/DeepLearning-keras/blob/main/ch8_1_text_generation_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYY_8Dam1Z54"
      },
      "source": [
        "# 8.1 LSTM으로 텍스트 생성하기\r\n",
        "\r\n",
        "- 딥러닝에서 시퀀스 데이터를 생성하는 일반적인 방법:\r\n",
        "\r\n",
        "이전 토큰을 입력으로 사용해서 시퀀스의 다음 1개 또는 몇개의 토큰을(RNN이나 convnet)으로 예측한다.\r\n",
        "\r\n",
        "- 언어모델을 이용한 텍스트 생성과정\r\n",
        "  - 언어 모델: 이전 토큰들이 주어졌을 때 다음 토큰의 확률을 모델링할 수 있는 네트워크\r\n",
        "  - 언어모델을 훈련한 후, 이 모델에서 샘플링을 할 수 있다. (샘플링: 새로운 시퀀스를 생성.)\r\n",
        "\r\n",
        "  1) 언어모델에 초기 텍스트 문자열을 주입하고 새로운 글자나 단어를 생성한다.\r\n",
        "  - 언어모델은 다음글자의 확률분포를 출력하고, 샘플링을 통해 새로운 단어를 생성한다. \r\n",
        "\r\n",
        "  2) 생성된 출력은 다시 입력 데이터로 추가되고, 위 과정을 여러번 반복한다.\r\n",
        "\r\n",
        "  3) 반복을 통해 모델이 훈련한 데이터 구조가 반영된 임의의 길이를 가진 시퀀스를 생성할 수 있다. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1dkiBiCDG_a"
      },
      "source": [
        "# 예시\r\n",
        "# 초기 텍스트 문자열 = 'The cat sat on the m'\r\n",
        "# 샘플링을 통해 생성된 다음 글자 = 'a'\r\n",
        "\r\n",
        "# 'a'를 입력데이터로 추가하여 문자열 'The cat sat on the ma' 를 입력모델에 주입\r\n",
        "# 샘플링을 통해 생성된 다음 글자 = 't'\r\n",
        "# 시퀀스 생성. 'The cat sat on the mat' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tAbD9jlC8wG"
      },
      "source": [
        "#### 8.1.3 샘플링 전략의 중요성\r\n",
        "\r\n",
        "- 확률적 샘플링: 다음 글자의 확률분포에서 샘플링하는 과정에 **무작위성**을 주입하는 방법\r\n",
        "\r\n",
        "작은 엔트로피는 예상가능한 구조를 가진 시퀀스를 생성(실제처럼 보임)\r\n",
        "\r\n",
        "높은 엔트로피는 창의적인 시퀀스를 생성.\r\n",
        "\r\n",
        "다양한 샘플링 전략으로 실험해보아야 한다.\r\n",
        "\r\n",
        "- Softmax temperature 파라미터 사용하기\r\n",
        "\r\n",
        "샘플링에 사용되는 확률분포의 엔트로피를 나타낸다.\r\n",
        "\r\n",
        "샘플링 과정에서 확률의 양을 조절하기 위해사용.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uImTcUfgEUMe"
      },
      "source": [
        "# temperature를 이용해 확률분포의 가중치 변경하기\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# original_distribution: 전체 합이 1인 넘파이 배열\r\n",
        "# temperature: 출력 분포의 엔트로피 양을 결정\r\n",
        "\r\n",
        "def reweight_distribution(original_distribution, temperature = 0.5):  \r\n",
        "  distribution = np.log(original_distribution) / temperature\r\n",
        "  distribution = np.exp(distribution)\r\n",
        "  return distribution / np.sum(distribution)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eacEcReBBkSX"
      },
      "source": [
        "#### LSTM 층을 사용한 예제\r\n",
        "\r\n",
        "텍스트말뭉치(corpus)에서 N개의 글자로 이루어진 문자열을 추출하여 주입.\r\n",
        "N+1 번째 글자를 예측하도록 훈련한다.\r\n",
        "\r\n",
        "모델의 출력은 출력 가능한 모든 글자에 해당하는 소프트맥스 값이다. (= 다음 글자의 확률 분포)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eFvwuSQBjii",
        "outputId": "8ce636ba-9225-47e7-adab-452469b30367"
      },
      "source": [
        "# 데이터 전처리\r\n",
        "\r\n",
        "import keras\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "path = keras.utils.get_file(\r\n",
        "    'nietzsche.txt',\r\n",
        "     origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\r\n",
        "\r\n",
        "text = open(path).read().lower() # 말뭉치를 소문자로 바꾸기\r\n",
        "print('말뭉치 크기:', len(text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "말뭉치 크기: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itDUkrUgPtA1"
      },
      "source": [
        "1. maxlen 길이를 가진 시퀀스를 중복해서 추출\r\n",
        "2. 추출된 시퀀스를 원-핫 인코딩으로 변환하고\r\n",
        "\r\n",
        "    크기가(sequences, maxlen, unique_characters) 인 3D 넘파이 배열 x로 합친다.\r\n",
        "    \r\n",
        "    동시에 훈련 샘플에 상응하는 타깃(다음 시퀀스)를 담은 배열 준비.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiYBgOMtJnDi",
        "outputId": "112f9540-774b-4ce4-b088-fd8c4f8e5104"
      },
      "source": [
        "# 1. 글자 시퀀스 추출.\r\n",
        "\r\n",
        "maxlen = 60 #60개의 글자로 된 시퀀스를 추출\r\n",
        "step = 3 #세글자씩 건너 뛰면서 새로운 시퀀스를 샘플링\r\n",
        "\r\n",
        "sentences = [] #추출한 시퀀스를 담을 리스트\r\n",
        "next_chars = [] #타깃을 담을 리스트(=시퀀스 다음 글자)\r\n",
        "\r\n",
        "\r\n",
        "for i in range(0, len(text)-maxlen, step): #마지막 for문을 돌 때, 즉 i = len(text)-60일때, 마지막까지 남아있는 60개의 글자로된 시퀀스를 추출함.\r\n",
        "  sentences.append(text[i: i+maxlen])\r\n",
        "  next_chars.append(text[i+maxlen])\r\n",
        "\r\n",
        "print('시퀀스 개수: ', len(sentences))\r\n",
        "\r\n",
        "chars = sorted(list(set(text))) #말뭉치에서 고유한 글자를 담은 리스트\r\n",
        "print('고유한 글자: ', len(chars))\r\n",
        "char_indices = dict((char, chars.index(char)) for char in chars) #chars 리스트에 있는 글자와 글자의 인덱스를 매핑한 딕셔너리\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "시퀀스 개수:  200278\n",
            "고유한 글자:  57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM96OfjlMZoF",
        "outputId": "9811efcb-dafe-43c8-c833-8cca6a0a6790"
      },
      "source": [
        "# 2. 시퀀스 벡터화.\r\n",
        "\r\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool) #(sequences, maxlen, unique_characters) 크기의 3D 넘파이 배열.\r\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool) #훈련 샘플에 상응하는 타깃(다음 시퀀스)을 담는 배열.\r\n",
        "\r\n",
        "print('x.shape: ', x.shape)\r\n",
        "\r\n",
        "# 글자를 원핫 인코딩하여 0과 1의 이진배열로 바꾸기\r\n",
        "\r\n",
        "for i, sentence in enumerate(sentences):\r\n",
        "  for t, char in enumerate(sentence):\r\n",
        "    x[i, t, char_indices[char]] = 1   #i번째 sentences차원의 t행 char열을 1로.\r\n",
        "\r\n",
        "  y[i, char_indices[next_chars[i]]] = 1\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape:  (200278, 60, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32dKEF1UQkEu",
        "outputId": "bbad8362-6bda-4821-a8fa-23c8744e914e"
      },
      "source": [
        "x[:1]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1k0p8heKtRb",
        "outputId": "752c5fe3-e2fc-4588-d431-3caa5451475a"
      },
      "source": [
        "len(x[x==1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12016680"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4XbWF1fQ7yL"
      },
      "source": [
        "- 네트워크 구성\r\n",
        "\r\n",
        "하나의 LSTM층 + Dense 분류기\r\n",
        "\r\n",
        "분류기는 가능한 모든 글자에 대한 소프트맥스 출력을 만든다. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuDWjinwMFIx"
      },
      "source": [
        "# 다음 글자를 예측하기 위한 단일 LSTM모델\r\n",
        "from keras import layers\r\n",
        "\r\n",
        "model = keras.models.Sequential()\r\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\r\n",
        "model.add(layers.Dense(len(chars), activation='softmax')) # 가능한 모든 글자의 소프트맥스\r\n",
        "\r\n",
        "# 모델 컴파일 설정\r\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVOmzD7USBIU"
      },
      "source": [
        "# 모델의 예측이 주어졌을 때, 새로운 글자를 샘플링\r\n",
        "\r\n",
        "def sample(preds, temperature=1.0):\r\n",
        "    preds = np.asarray(preds).astype('float64')\r\n",
        "    preds = np.log(preds) / temperature\r\n",
        "    exp_preds = np.exp(preds)\r\n",
        "    preds = exp_preds / np.sum(exp_preds)\r\n",
        "    probas = np.random.multinomial(1, preds, 1) # np.random.multinomial() 다항분포를 시뮬레이션\r\n",
        "\r\n",
        "    return np.argmax(probas)  \r\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uo7rexLrS5A2",
        "outputId": "0a203de8-9671-49e0-eff7-d2cad5695c65"
      },
      "source": [
        "# 훈련하여 텍스트 생성\r\n",
        "\r\n",
        "import random\r\n",
        "import sys\r\n",
        "\r\n",
        "random.seed(42)\r\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\r\n",
        "\r\n",
        "for epoch in range(1, 60):\r\n",
        "  model.fit(x, y, batch_size=128, epochs =1) #데이터에서 한번만 반복해서 모델 학습\r\n",
        "\r\n",
        "  seed_text = text[start_index: start_index + maxlen] # 무작위로 시드 텍스트를 선택\r\n",
        "  print('--시드 텍스트: \"' + seed_text + '\"')\r\n",
        "\r\n",
        "  for temperature in [0.2, 0.5, 1.0, 1.2]: # 여러가지 샘플링 temperature를 시도\r\n",
        "    print('----temperature: ', temperature)\r\n",
        "    generated_text = seed_text\r\n",
        "    sys.stdout.write(generated_text) #개행없이 print. 모든 문자열이 연달아 출력.\r\n",
        "\r\n",
        "\r\n",
        "    # 시드 텍스트에서 시작해서 400개의 글자를 생성\r\n",
        "    for i in range(400): \r\n",
        "      # 지금까지 생성된 글자를 원-핫 인코딩으로 바꾸기.\r\n",
        "      sampled = np.zeros((1, maxlen, len(chars)))\r\n",
        "      for t, char in enumerate(generated_text):\r\n",
        "        sampled[0, t, char_indices[char]] =1.\r\n",
        "\r\n",
        "      # 다음 글자를 샘플링\r\n",
        "      preds = model.predict(sampled, verbose=0)[0]\r\n",
        "      next_index = sample(preds, temperature) #sample함수를 통해 다음 글자를 샘플링.\r\n",
        "      next_char = chars[next_index]\r\n",
        "\r\n",
        "      generated_text += next_char           \r\n",
        "      generated_text = generated_text[1:]\r\n",
        "\r\n",
        "\r\n",
        "      sys.stdout.write(next_char)\r\n",
        "      sys.stdout.flush()\r\n",
        "\r\n",
        "    print()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1565/1565 [==============================] - 262s 167ms/step - loss: 2.2503\n",
            "--시드 텍스트: \"the slowly ascending ranks and classes, in which,\n",
            "through fo\"\n",
            "----temperature:  0.2\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through for the greet will the complear and invent of the self-its have have have the have and dengerous of the gree dere and the seence of the stand it is and the propossion and the are in the are and the still the seen have the will the same the soulting it is all and soul, and the conderes of the paristance of the way the have the have the seeptes of the good and sould to and the great of the self as a p\n",
            "----temperature:  0.5\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through for only orwer have have the belowicy of the remay and the god in\n",
            "its still we dengers\" of like of the formest man the and and something refere of the enterenties and the most have heartest in the person the against in something accompate of way as the are of the enever of the there or the learte as it is the enes and to have only world and as he fained have have live of consernence to the ene all t\n",
            "----temperature:  1.0\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through foul\n",
            "hy thinkel, perhacdity propusso as they: been way\n",
            "ocppreentafher eapical posseannly, and\n",
            "itself\n",
            "other to eagles. them be tom their of\n",
            "centions.--wilty if revere distelier inismulf and the onry\n",
            "manger's longure: sulfedemsional\n",
            "tnour dipte--smentoure excable roderaked dene--and sumplents\n",
            "or puivisard, for   dyltysion withoun have theread, a think, that world hapd couprive dechessy and\n",
            "the hemal o\n",
            "----temperature:  1.2\n",
            "the slowly ascending ranks and classes, in which,\n",
            "through for ror order inteness of the lee-ngoundowy on gere: he lod inteyiiseness:\n",
            "world not foo the met lems eerm, heritusiading abow, which\n",
            "inlivitates or defing hibhimys,\n",
            "he wills\n",
            "for amposdess of the\n",
            "decesiamyed why good. indorgined--be explreation not that in the higuar puss., fouse as express, fissy, cthis does it_is\n",
            "a\n",
            "ond\n",
            "seefles\n",
            "mey,\n",
            "heart-an tolners\n",
            "sweresth,--our and plaun\n",
            "foot inthilitaterugly, h\n",
            "  74/1565 [>.............................] - ETA: 4:12 - loss: 1.6401"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4c6e21d91294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#데이터에서 한번만 반복해서 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mseed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 무작위로 시드 텍스트를 선택\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNo2MCHPXLUM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}